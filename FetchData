#!/usr/bin/perl
#
# FetchData
#
# Find the most current version at http://service.iris.edu/clients/
#
# Fetch data and related metadata from web services.  The default web
# service are from the IRIS DMC, other FDSN web services may be
# specified by setting the following environment variables:
#
# SERVICEBASE = the base URI of the service(s) to use (http://service.iris.edu/)
# TIMESERIESWS = complete URI of service (http://service.iris.edu/fdsnws/dataselect/1)
# METADATAWS = complete URI of service (http://service.iris.edu/fdsnws/station/1)
# SACPZWS = complete URI of service (http://service.iris.edu/irisws/sacpz/1)
# RESPWS = complete URI of service (http://service.iris.edu/irisws/resp/1)
#
# This program is primarily written to select and fetch waveform data
# but can also fetch metadata and response information if those
# services exist at the specified data center.  The fdsnws-dataselect
# service is a minimum requirement for use of this script. The
# fdsnws-station service is required if metadata is to be retrieved or
# if geographic selection options are used.
#
# Dependencies: This script should run without problems on Perl
# release 5.10 or newer, older versions of Perl might require the
# installation of the following modules (and their dependencies):
#   XML::SAX
#   Bundle::LWP (libwww-perl)
#
# Installation of the XML::SAX::ExpatXS module can significantly
# speed up the parsing of metadata results returned as XML.
#
## Data selection
#
# Data is generally selected by specifying network, station, location,
# channel, quality, start time and end time.  The name parameters may
# contain wildcard characters.  All input options are optional but
# waveform requests should include a time window.  Data may be
# selected one of three ways:
#
# 1) Command line arguments: -N, -S, -L, -C, -Q, -s, -e
#
# 2) A BREQ_FAST formatted file, http://www.iris.edu/manuals/breq_fast.htm
#
# 3) A selection file containing a list of:
#    Net Sta Loc Chan Start End
#
# Example selection file contents:
# II BFO 00 BHZ 2011-01-01T00:00:00 2011-01-01T01:00:00
# IU ANMO 00 BHZ 2011-01-01T00:00:00 2011-01-01T01:00:00
# IU COLA 00 BHZ 2011-01-01T00:00:00 2011-01-01T01:00:00
#
# For the command line arguments and the selection file the network,
# station location and channel fields may contain the common * and ?
# wildcards, meaning zero-to-many and a single character respectively.
# These fields may also be comma-separated lists, for example, the
# network may be specified as II,IU,TA to select three networks.
#
## Data output
#
# miniSEED: If the -o option is used to specify an output file
# waveform data will be requested based on the selection and all
# written to the single file.
#
# metadata: If the -m option is used to specifiy a metadata file a
# line will be written to the file for each channel epoch and will
# contain:
# "net|sta|loc|chan|lat|lon|elev|depth|azimuth|dip|instrument|scale|scalefreq|scaleunits|samplerate|start|end"
#
# This metadata file can be used directly with mseed2sac or tracedsp
# to create SAC files including basic metadata.
#
# SAC P&Zs: If the -sd option is given SAC Poles and Zeros will be
# fetched and a file for each channel will be written to the specified
# directory with the name 'SACPZ.Net.Sta.Loc.Chan'.  If this option is
# used while fetching waveform data, only channels which returned
# waveforms will be requested.
#
# RESP: If the -rd option is given SEED RESP (as used by evalresp)
# will be fetched and a file for each channel will be written to the
# specified directory with the name 'RESP.Net.Sta.Loc.Chan'.  If this
# option is used while fetching waveform data, only channels which
# returned waveforms will be requested.
#
#
# ## Change history ##
#
# 2013.042:
#  - Rename to FetchData (from FetchBulkData), truncate change log.
#  - Use the LWP::UserAgent method env_proxy() to check for and use connection
#  proxy information from environment variables (e.g. http_proxy).
#  - Add checking of environment variables that will override the web
#  service base path (i.e. host name).
#  - Change to allow data requests without metadata fetching.
#
# 2013.067:
#  - Changed metadata parsing to understand FDSN StationXML schema.
#  - Create override service URLs for ws-sacpz and ws-resp until they
#  are migrated to service.iris.edu.
#
# 2013.074:
#  - Add work around for bug in Perl's Digest Authorization headers
#  that conflicts with pedantic behavior of Apache Tomcat, eventually
#  Tomcat will be more lenient and this work around will be removed.
#
# 2013.077:
#  - Convert metadata output line to be bar (|) separated instead of
#  comma separated and leave dip in SEED convention.
#  - Do not translate commas to semicolons in instrument name in metadata.
#
# 2013.086
#  - Remove code to filter Authorization headers, Apache Tomcat has been fixed
#  to accept Digest Authentication credentials as submitted by libwww/LWP.
#
# 2013.118
#  - Fix parsing of start and end times from metadata that are used when no
#  start and/or end is specified by the caller.
#
# 2013.150
#  - Allow dash characters in breqfast formatted requests for the network
#  fields to support virtual networks that use dashes.
#
# 2013.186
#  - Change service URL override command line options to match
#  environment variables.
#
# 2013.197
#  - Fix parsing of element values of "0".
#
# 2013.198
#  - Add test for minimum version of LWP (libwww) module of 5.806.
#
# Author: Chad Trabant, IRIS Data Management Center

use strict;
use File::Basename;
use Getopt::Long;
use LWP 5.806; # Require minimum version
use LWP::UserAgent;
use HTTP::Status qw(status_message);
use HTTP::Date;
use Time::HiRes;

my $version = "2013.198";

my $scriptname = basename($0);

# Default web service base
my $servicebase = 'http://service.iris.edu';

# Check for environment variable overrides for servicebase
$servicebase = $ENV{'SERVICEBASE'} if ( exists $ENV{'SERVICEBASE'} );

# Web service for time series data
my $timeseriesservice = "$servicebase/fdsnws/dataselect/1";

# Check for environment variable override for timeseriesservice
$timeseriesservice = $ENV{'TIMESERIESWS'} if ( exists $ENV{'TIMESERIESWS'} );

# Default web service for metadata
my $metadataservice = "$servicebase/fdsnws/station/1";

# Check for environment variable override for metadataservice
$metadataservice = $ENV{'METADATAWS'} if ( exists $ENV{'METADATAWS'} );

# Web service for SAC P&Z
my $sacpzservice = "$servicebase/irisws/sacpz/1";
# Until this service is migrated here is an override
my $sacpzservice = "http://www.iris.edu/ws/sacpz";

# Check for environment variable override for sacpzservice
$sacpzservice = $ENV{'SACPZWS'} if ( exists $ENV{'SACPZWS'} );

# Web service for RESP
my $respservice = "$servicebase/irisws/resp/1";
# Until this service is migrated here is an override
my $respservice = "http://www.iris.edu/ws/resp";

# Check for environment variable override for respservice
$respservice = $ENV{'RESPWS'} if ( exists $ENV{'RESPWS'} );

# HTTP UserAgent reported to web services
my $useragent = "$scriptname/$version Perl/$] " . new LWP::UserAgent->_agent;

# Waveform data request group size in terms of station-days
my $groupstadays = 30;


my $usage      = undef;
my $verbose    = undef;
my $nobsprint  = undef;

my $net        = undef;
my $sta        = undef;
my $loc        = undef;
my $chan       = undef;
my $qual       = "B";
my $starttime  = undef;
my $endtime    = undef;
my @latrange   = ();      # (minlat:maxlat)
my @lonrange   = ();      # (minlon:maxlon)
my @degrange   = ();      # (lat:lon:maxradius[:minradius])
my $selectfile = undef;
my $bfastfile  = undef;
my $mslopt     = undef;
my $lsoopt     = undef;
my $appname    = undef;
my $auth       = undef;
my $outfile    = undef;
my $sacpzdir   = undef;
my $respdir    = undef;
my $metafile   = undef;

# Parse command line arguments
Getopt::Long::Configure ("bundling_override");
my $getoptsret = GetOptions ( 'help|usage|h'   => \$usage,
                              'verbose|v+'     => \$verbose,
                              'nobs'           => \$nobsprint,
                              'net|N=s'        => \$net,
                              'sta|S=s'        => \$sta,
                              'loc|L=s'        => \$loc,
                              'chan|C=s'       => \$chan,
                              'qual|Q=s'       => \$qual,
			      'starttime|s=s'  => \$starttime,
			      'endtime|e=s'    => \$endtime,
			      'lat=s'          => \@latrange,
			      'lon=s'          => \@lonrange,
			      'radius=s'       => \@degrange,
			      'selectfile|l=s' => \$selectfile,
			      'bfastfile|b=s'  => \$bfastfile,
			      'msl=s'          => \$mslopt,
			      'lso'            => \$lsoopt,
			      'appname|A=s'    => \$appname,
			      'auth|a=s'       => \$auth,
			      'outfile|o=s'    => \$outfile,
			      'sacpzdir|sd=s'  => \$sacpzdir,
			      'respdir|rd=s'   => \$respdir,
			      'metafile|m=s'   => \$metafile,
			      'timeseriesws=s' => \$timeseriesservice,
			      'metadataws=s'   => \$metadataservice,
			      'sacpzws=s'      => \$sacpzservice,
			      'respws=s'       => \$respservice,
			    );

my $required =  ( defined $net || defined $sta ||
		  defined $loc || defined $chan ||
		  scalar @latrange || scalar @lonrange || scalar @degrange ||
		  defined $starttime || defined $endtime ||
		  defined $selectfile || defined $bfastfile );

if ( ! $getoptsret || $usage || ! $required ) {
  print "$scriptname: collect time series and related metadata (version $version)\n";
  print "http://service.iris.edu/clients/\n\n";
  print "Usage: $scriptname [options]\n\n";
  print " Options:\n";
  print " -v                Increase verbosity, may be specified multiple times\n";
  print " -N,--net          Network code, list and wildcards (* and ?) accepted\n";
  print " -S,--sta          Station code, list and wildcards (* and ?) accepted\n";
  print " -L,--loc          Location ID, list and wildcards (* and ?) accepted\n";
  print " -C,--chan         Channel codes, list and wildcards (* and ?) accepted\n";
  print " -Q,--qual         Quality indicator, default is best\n";
  print " -s starttime      Specify start time (YYYY-MM-DD,HH:MM:SS.ssssss)\n";
  print " -e endtime        Specify end time (YYYY-MM-DD,HH:MM:SS.ssssss)\n";
  print " --lat min:max     Specify a minimum and/or maximum latitude range\n";
  print " --lon min:max     Specify a minimum and/or maximum longitude range\n";
  print " --radius lat:lon:maxradius[:minradius]\n";
  print "                     Specify circular region with optional minimum radius\n";
  print " -l listfile       Read list of selections from file\n";
  print " -b bfastfile      Read list of selections from BREQ_FAST file\n";
  print " -msl length       Limit returned data to a minimum segment length\n";
  print " -lso              Limit returned data to the longest segment only\n";
  print " -A appname        Application/version string for identification\n";
  print " -a user:pass      User and password for access to restricted data\n";
  print "\n";
  print " -o outfile        Fetch time series data and write to output file\n";
  print " -sd sacpzdir      Fetch SAC P&Zs and write files to sacpzdir\n";
  print " -rd respdir       Fetch RESP and write files to respdir\n";
  print " -m metafile       Write basic metadata to specified file\n";
  print "\n";
  exit 1;
}

if ( ! $outfile && ! $metafile && ! $sacpzdir && ! $respdir ) {
  die "No output options specified, try -h for usage information\n";
}

# Print script name and local time string
if ( $verbose ) {
  my ($sec,$min,$hour,$mday,$mon,$year,$wday,$yday,$isdst) = localtime(time);
  printf STDERR "$scriptname ($version) at %4d-%02d-%02d %02d:%02d:%02d\n", $year+1900, $mon+1, $mday, $hour, $min, $sec;
}

# Check for existence of output directories
if ( $sacpzdir && ! -d "$sacpzdir" ) {
  die "Cannot find SAC P&Zs output directory: $sacpzdir\n";
}
if ( $respdir && ! -d "$respdir" ) {
  die "Cannot find RESP output directory: $respdir\n";
}

# Check for time window if requesting time series data
if ( $outfile && ( ! defined $selectfile && ! defined $bfastfile &&
		   ( ! defined $starttime || ! defined $endtime ) ) ) {
  die "Cannot request time series data without start and end times\n";
}

# Normalize time strings given on the command line
if ( $starttime ) {
  my ($year,$month,$mday,$hour,$min,$sec,$subsec) = split (/[-:,.\s\/T]/, $starttime);
  $starttime = sprintf ("%04d-%02d-%02dT%02d:%02d:%02d", $year, $month, $mday, $hour, $min, $sec);
  $starttime .= ".$subsec" if ( $subsec );
}

if ( $endtime ) {
  my ($year,$month,$mday,$hour,$min,$sec,$subsec) = split (/[-:,.\s\/T]/, $endtime);
  $endtime = sprintf ("%04d-%02d-%02dT%02d:%02d:%02d", $year, $month, $mday, $hour, $min, $sec);
  $endtime .= ".$subsec" if ( $subsec );
}

# Validate and prepare lat, lon and radius input
if ( scalar @latrange ) {
  @latrange = split (/:/, $latrange[0]);

  if ( defined $latrange[0] && ($latrange[0] < -90.0 || $latrange[0] > 90.0) ) {
    die "Minimum latitude out of range: $latrange[0]\n";
  }
  if ( defined $latrange[1] && ($latrange[1] < -90.0 || $latrange[1] > 90.0) ) {
    die "Maximum latitude out of range: $latrange[1]\n";
  }
}
if ( scalar @lonrange ) {
  @lonrange = split (/\:/, $lonrange[0]);

  if ( defined $lonrange[0] && ($lonrange[0] < -180.0 || $lonrange[0] > 180.0) ) {
    die "Minimum longitude out of range: $lonrange[0]\n";
  }
  if ( defined $lonrange[1] && ($lonrange[1] < -180.0 || $lonrange[1] > 180.0) ) {
    die "Maximum longitude out of range: $lonrange[1]\n";
  }
}
if ( scalar @degrange ) {
  @degrange = split (/\:/, $degrange[0]);

  if ( scalar @degrange < 3 || scalar @degrange > 4 ) {
    die "Unrecognized radius specification: @degrange\n";
  }
  if ( defined $degrange[0] && ($degrange[0] < -90.0 || $degrange[0] > 90.0) ) {
    die "Radius latitude out of range: $degrange[0]\n";
  }
  if ( defined $degrange[1] && ($degrange[1] < -180.0 || $degrange[1] > 180.0) ) {
    die "Radius longitude out of range: $degrange[1]\n";
  }
}

# An array to hold data selections
my @selections = ();

# Add command line selection to list
if ( defined $net || defined $sta || defined $loc || defined $chan ||
     defined $starttime || defined $endtime ) {
  push (@selections,"$net|$sta|$loc|$chan|$starttime|$endtime");
}

# Read selection list file
if ( $selectfile ) {
  print STDERR "Reading data selection from list file '$selectfile'\n";
  &ReadSelectFile ($selectfile);
}

# Read BREQ_FAST file
if ( $bfastfile ) {
  print STDERR "Reading data selection from BREQ_FAST file '$bfastfile'\n";
  &ReadBFastFile ($bfastfile);
}

# Report complete data selections
if ( $verbose > 2 ) {
  print STDERR "== Data selections ==\n";
  foreach my $select ( @selections ) {
    print STDERR "    $select\n";
  }
  print STDERR "Latitude range: $latrange[0] : $latrange[1]\n" if ( scalar @latrange );
  print STDERR "Longitude range: $lonrange[0] : $lonrange[1]\n" if ( scalar @lonrange );
  print STDERR "Radius range: $degrange[0] : $degrange[1] : $degrange[2] : $degrange[3]\n" if ( scalar @degrange );
}

# Add blank request entry if selections have been implicitly identified by location ranges
if ( ! scalar @selections && (scalar @latrange || scalar @lonrange || scalar @degrange) ) {
  push (@selections,"|||||");
}

# An array to hold channel list and metadata
my %request = (); # Value is metadata range for selection
my @metadata = ();
my $metadataxml;

# Fetch metadata from the station web service if metadata output file has been
# specified or if geographic range selection is requested.
# This processing will populate the request hash with entries matching metadata
if ( $metafile || $sacpzdir || $respdir
     || scalar @latrange || scalar @lonrange || scalar @degrange ) {
  foreach my $selection ( @selections ) {
    my ($snet,$ssta,$sloc,$schan,$sstart,$send) = split (/\|/,$selection);
    &FetchMetaData($snet,$ssta,$sloc,$schan,$sstart,$send);
  }
}
# Build request hash directly from selections
else {
  foreach my $selection ( @selections ) {
    my ($snet,$ssta,$sloc,$schan,$sstart,$send) = split (/\|/,$selection);

    # Subsitute non-specified fields with wildcards
    $snet = "*" if ( ! $snet );
    $ssta = "*" if ( ! $ssta );
    $sloc = "*" if ( ! $sloc );
    $schan = "*" if ( ! $schan );

    $request{"$snet|$ssta|$sloc|$schan|$sstart|$send"} = "$sstart|$send";
  }
}

# Report complete data request
if ( $verbose > 2 ) {
  print STDERR "== Request list ==\n";
  foreach my $req ( sort keys %request ) {
    print STDERR "    $req (metadata: $request{$req})\n";
  }
}

# Track bytes downloaded in callback handlers
my $datasize = 0;

# Fetch time series data if output file specified
&FetchTimeSeriesData() if ( $outfile );

# Collect SAC P&Zs if output directory specified
&FetchSACPZ() if ( $sacpzdir );

# Collect RESP if output directory specified
&FetchRESP() if ( $respdir );

# Write metadata to file
if ( $metafile ) {
  if ( scalar @metadata <= 0 ) {
    printf STDERR "No metdata available\n", scalar @metadata;
  }
  else {
    printf STDERR "Writing metadata (%d channel epochs) file\n", scalar @metadata if ( $verbose );

    open (META, ">$metafile") || die "Cannot open metadata file '$metafile': $!\n";

    # Print header line
    print META "#net|sta|loc|chan|lat|lon|elev|depth|azimuth|dip|instrument|scale|scalefreq|scaleunits|samplerate|start|end\n";

    foreach my $channel ( sort @metadata ) {
      my ($net,$sta,$loc,$chan,$start,$end,$lat,$lon,$elev,$depth,$azimuth,$dip,$instrument,$samplerate,$sens,$sensfreq,$sensunit) =
	split (/\|/, $channel);

      $sensfreq = sprintf ("%0g", $sensfreq);
      $samplerate = sprintf ("%0g", $samplerate);

      print META "$net|$sta|$loc|$chan|$lat|$lon|$elev|$depth|$azimuth|$dip|$instrument|$sens|$sensfreq|$sensunit|$samplerate|$start|$end\n";
    }

    close META;
  }
}

my ($sec,$min,$hour,$mday,$mon,$year,$wday,$yday,$isdst) = localtime(time);
printf STDERR "DONE at %4d-%02d-%02d %02d:%02d:%02d\n", $year+1900, $mon+1, $mday, $hour, $min, $sec;
## End of main


######################################################################
# ReadSelectFile:
#
# Read selection list file and add entries to the @selections array.
#
# Selection lines are expected to be in the following form:
#
# "Net Sta Loc Chan Start End"
#
# The Net, Sta, Loc and Channel fields are required and can be
# specified as wildcards.
######################################################################
sub ReadSelectFile {
  my $selectfile = shift;

  open (SF, "<$selectfile") || die "Cannot open '$selectfile': $!\n";

  foreach my $line ( <SF> ) {
    chomp $line;
    next if ( $line =~ /^\#/ ); # Skip comment lines

    my ($net,$sta,$loc,$chan,$start,$end) = split (' ', $line);

    next if ( ! defined $chan );

    # Normalize time strings
    if ( $start ) {
      my ($year,$month,$mday,$hour,$min,$sec,$subsec) = split (/[-:,.\s\/T]/, $start);
      $start = sprintf ("%04d-%02d-%02dT%02d:%02d:%02d", $year, $month, $mday, $hour, $min, $sec);
      $start .= ".$subsec" if ( $subsec );
    }

    if ( $end ) {
      my ($year,$month,$mday,$hour,$min,$sec,$subsec) = split (/[-:,.\s\/T]/, $end);
      $end = sprintf ("%04d-%02d-%02dT%02d:%02d:%02d", $year, $month, $mday, $hour, $min, $sec);
      $end .= ".$subsec" if ( $subsec );
    }

    # Add selection to global list
    push (@selections,"$net|$sta|$loc|$chan|$start|$end");
  }

  close SF;
} # End of ReadSelectFile()


######################################################################
# ReadBFastFile:
#
# Read BREQ_FAST file and add entries to the @selections array.
#
######################################################################
sub ReadBFastFile {
  my $bfastfile = shift;

  open (BF, "<$bfastfile") || die "Cannot open '$bfastfile': $!\n";

  my $linecount = 0;
  BFLINE: foreach my $line ( <BF> ) {
    chomp $line;
    $linecount++;
    next if ( ! $line ); # Skip empty lines

    # Capture .QUALTIY header
    if ( $line =~ /^\.QUALITY .*$/ ) {
      ($qual) = $line =~ /^\.QUALITY ([DRQMBE])/;
      next;
    }

    next if ( $line =~ /^\./ ); # Skip other header lines

    my ($sta,$net,$syear,$smon,$sday,$shour,$smin,$ssec,$eyear,$emon,$eday,$ehour,$emin,$esec,$count,@chans) = split (' ', $line);

    # Simple validation of BREQ FAST fields
    if ( $sta !~ /^[A-Za-z0-9*?]{1,5}$/ ) {
      print "Unrecognized station code: '$sta', skipping line $linecount\n" if ( $verbose );
      next;
    }
    if ( $net !~ /^[-_A-Za-z0-9*?]+$/ ) {
      print "Unrecognized network code: '$net', skipping line $linecount\n" if ( $verbose );
      next;
    }
    if ( $syear !~ /^\d\d\d\d$/ ) {
      print "Unrecognized start year: '$syear', skipping line $linecount\n" if ( $verbose );
      next;
    }
    if ( $smon !~ /^\d{1,2}$/ ) {
      print "Unrecognized start month: '$smon', skipping line $linecount\n" if ( $verbose );
      next;
    }
    if ( $sday !~ /^\d{1,2}$/ ) {
      print "Unrecognized start day: '$sday', skipping line $linecount\n" if ( $verbose );
      next;
    }
    if ( $shour !~ /^\d{1,2}$/ ) {
      print "Unrecognized start hour: '$shour', skipping line $linecount\n" if ( $verbose );
      next;
    }
    if ( $smin !~ /^\d{1,2}$/ ) {
      print "Unrecognized start min: '$smin', skipping line $linecount\n" if ( $verbose );
      next;
    }
    if ( $ssec !~ /^\d{1,2}\.?\d{0,6}?$/ ) {
      print "Unrecognized start seconds: '$ssec', skipping line $linecount\n" if ( $verbose );
      next;
    }
    if ( $eyear !~ /^\d\d\d\d$/ ) {
      print "Unrecognized end year: '$eyear', skipping line $linecount\n" if ( $verbose );
      next;
    }
    if ( $emon !~ /^\d{1,2}$/ ) {
      print "Unrecognized end month: '$emon', skipping line $linecount\n" if ( $verbose );
      next;
    }
    if ( $eday !~ /^\d{1,2}$/ ) {
      print "Unrecognized end day: '$eday', skipping line $linecount\n" if ( $verbose );
      next;
    }
    if ( $ehour !~ /^\d{1,2}$/ ) {
      print "Unrecognized end hour: '$ehour', skipping line $linecount\n" if ( $verbose );
      next;
    }
    if ( $emin !~ /^\d{1,2}$/ ) {
      print "Unrecognized end min: '$emin', skipping line $linecount\n" if ( $verbose );
      next;
    }
    if ( $esec !~ /^\d{1,2}\.?\d{0,6}?$/ ) {
      print "Unrecognized end seconds: '$esec', skipping line $linecount\n" if ( $verbose );
      next;
    }
    if ( $count !~ /^\d+$/ || $count <= 0 ) {
      print "Invalid channel count field: '$count', skipping line $linecount\n" if ( $verbose );
      next;
    }
    if ( scalar @chans <= 0 ) {
      print "No channels specified, skipping line $linecount\n" if ( $verbose );
      next;
    }

    # Extract location ID if present, i.e. if channel count is one less than present
    my $loc = undef;
    $loc = pop @chans if ( scalar @chans == ($count+1) );

    if ( $loc && $loc !~ /^[A-Za-z0-9*?\-]{1,2}$/ ) {
      print "Unrecognized location ID: '$loc', skipping line $linecount\n" if ( $verbose );
      next;
    }

    foreach my $chan ( @chans ) {
      if ( $chan !~ /^[A-Za-z0-9*?]{3,3}$/ ) {
	print "Unrecognized channel codes: '$chan', skipping line $linecount\n" if ( $verbose );
	next BFLINE;
      }
    }

    if ( scalar @chans != $count ) {
      printf "Channel count field ($count) does not match number of channels specified (%d), skipping line $linecount\n",
	scalar @chans if ( $verbose );
      next;
    }

    # Normalize time strings
    my ($ssec,$ssub) = split (/\./, $ssec);
    my $start = sprintf ("%04d-%02d-%02dT%02d:%02d:%02d", $syear, $smon, $sday, $shour, $smin, $ssec);
    $start .= ".$ssub" if ( $ssub );
    my ($esec,$esub) = split (/\./, $esec);
    my $end = sprintf ("%04d-%02d-%02dT%02d:%02d:%02d", $eyear, $emon, $eday, $ehour, $emin, $esec);
    $end .= ".$esub" if ( $esub );

    # Add selection to global list for each channel
    foreach my $chan ( @chans ) {
      push (@selections,"$net|$sta|$loc|$chan|$start|$end");
    }
  }

  close BF;
} # End of ReadBFastFile()


######################################################################
# FetchTimeSeriesData:
#
# Collect time series data for each entry in the %request hash.  All
# returned data is written to the global output file (outfile).
#
# The request list is separatated into groups where the group size is
# defined in terms of station-days.  If the request for a group fails
 # it will be retried, after too many failures.
#
######################################################################
sub FetchTimeSeriesData {
  # Open output file
  open (OUT, ">$outfile") || die "Cannot open output file '$outfile': $!\n";

  # Create HTTP user agent
  my $ua = RequestAgent->new();
  $ua->env_proxy;

  my $count = 0;

  # Determine request data groups to avoid single large requests
  my @grouprequest = ();

  my $groupdays = 0;
  my $groupidx = 0;
  my $groupsta = undef;
  foreach my $req ( sort keys %request ) {
    my ($wnet,$wsta,$wloc,$wchan,$wstart,$wend) = split (/\|/, $req);
    $count++;

    # Determine day coverage for this request
    my $rstartepoch = str2time ($wstart);
    my $rendepoch = str2time ($wend);
    my $reqdays = int ((($rendepoch - $rstartepoch) / 86400.0) + 0.5);
    $reqdays = 1 if ( $reqdays < 1 );

    $groupsta = $wsta if ( ! defined $groupsta );

    # Assume first request for a station represents all channels in terms of days
    if ( $wsta ne $groupsta ) {
      $groupdays += $reqdays;
      $groupsta = $wsta;
    }

    # If beyond groupstadays move to the next group
    if ( $groupdays >= $groupstadays ) {
      $groupdays = 0;
      $groupidx++;
    }

    # Add request to current group
    push (@{$grouprequest[$groupidx]}, "$wnet $wsta $wloc $wchan $wstart $wend");
  }

  if ( ! $count ) {
    print STDERR "No data selections to request\n";
    return;
  }

  print STDERR "Fetching time series data ($count selections)\n" if ( $verbose );
  my $ftime = Time::HiRes::time;
  my $totalbytes = 0;

  # Request each data group
  my $groupnum = 1;
  my $groupcnt = scalar @grouprequest;
  my $redocnt = 0;
  my $outoffset = 0;
  foreach my $groupref ( @grouprequest ) {
  REDOGROUP:
    # Create web service URI
    my $query = ( $auth ) ? "queryauth" : "query";
    my $uri = "${timeseriesservice}/$query";

    # Create POST data selection: specify options followed by selections
    my $postdata = "quality=$qual\n";
    $postdata .= "minimumlength=$mslopt\n" if ( defined $mslopt );
    $postdata .= "longestonly=true\n" if ( defined $lsoopt );

    foreach my $req ( @{$groupref} ) {
      $postdata .= "$req\n";
    }

    print STDERR "Time series URI: '$uri'\n" if ( $verbose > 1 );
    print STDERR "Data selection (POST):\n$postdata" if ( $verbose > 1 );

    print STDERR "Downloading time series data (group $groupnum of $groupcnt) :: " if ( $verbose );

    $datasize = 0;

    # Fetch time series data from web service using callback routine
    my $response = $ua->post($uri, Content => $postdata, ':content_cb' => \&DLCallBack );

    if ( $response->code == 204 ) {
      print (STDERR "No data available\n") if ( $verbose );
    }
    elsif ( $response->code == 401 ) {
      print (STDERR "AUTHORIZATION FAILED, username and password not recognized\n");
      last;
    }
    elsif ( ! $response->is_success() ) {
      print (STDERR "Error fetching data: "
	     . $response->code . " :: " . status_message($response->code) . "\n");
      print STDERR "------\n" . $response->decoded_content . "\n------\n";
      print STDERR "  URI: '$uri'\n" if ( $verbose > 1 );

      # For real output files rewind position to the end of the last group data
      seek (OUT, $outoffset, 0) if ( $outfile ne "-" );

      # Retry in 10 seconds or give up if already tried 60 times.
      if ( $response->code != 400 && $redocnt < 60 ) {
	print STDERR "Retrying request in 10 seconds\n";
	sleep 10;
	$redocnt++;
	goto REDOGROUP;
      }
      else {
	print STDERR "Too many retries, giving up.\n";
	last;
      }
    }
    else {
      printf (STDERR "%s\n", ($nobsprint)?sizestring($datasize):"") if ( $verbose );
    }

    # Get ready for next group
    $redocnt = 0;
    $groupnum++;
    $outoffset = tell (OUT);
    $totalbytes += $datasize;
  }

  close OUT;

  my $duration = Time::HiRes::time - $ftime;
  my $rate = $totalbytes/(($duration)?$duration:0.000001);
  printf (STDERR "Received %s of time series data in %.1f seconds (%s/s)\n",
	  sizestring($totalbytes), $duration, sizestring($rate));

  # Remove empty file
  unlink $outfile if ( -z $outfile );
} # End of FetchTimeSeriesData


######################################################################
# FetchSACPZ:
#
# Fetch SAC Poles and Zeros for each entry in the %request hash with a
# defined value.  The result for each channel is written to a separate
# file in the specified directory.
#
######################################################################
sub FetchSACPZ {
  # Create HTTP user agent
  my $ua = RequestAgent->new();
  $ua->env_proxy;

  my $count = 0;
  my $total = 0;
  foreach my $req ( keys %request ) { $total++ if ( defined $request{$req} ); }

  print STDERR "Fetching SAC Poles and Zeros\n" if ( $verbose );
  my $ftime = Time::HiRes::time;
  my $totalbytes = 0;

  foreach my $req ( sort keys %request ) {
    # Skip entries with values not set, perhaps no data was fetched
    next if ( ! defined $request{$req} );

    my ($rnet,$rsta,$rloc,$rchan,$rstart,$rend) = split (/\|/, $req);
    my ($mstart,$mend) = split (/\|/, $request{$req});
    $count++;

    # Generate output file name and open
    my $sacpzfile = "$sacpzdir/SACPZ.$rnet.$rsta.$rloc.$rchan";
    if ( ! open (OUT, ">$sacpzfile") ) {
      print STDERR "Cannot open output file '$sacpzfile': $!\n";
      next;
    }

    # Use metadata start and end if not specified
    $rstart = $mstart if ( ! $rstart );
    $rend = $mend if ( ! $rend );

    # Create web service URI
    my $uri = "${sacpzservice}/query?net=$rnet&sta=$rsta&loc=$rloc&cha=$rchan";
    $uri .= "&starttime=$rstart" if ( $rstart );
    $uri .= "&endtime=$rend" if ( $rend );

    print STDERR "SAC-PZ URI: '$uri'\n" if ( $verbose > 1 );

    print STDERR "Downloading $sacpzfile ($count/$total) :: " if ( $verbose );

    $datasize = 0;

    # Fetch data from web service using callback routine
    my $response = $ua->get($uri, ':content_cb' => \&DLCallBack );

    if ( $response->code == 404 || $response->code == 204 ) {
      print (STDERR "No data available\n") if ( $verbose );
    }
    elsif ( ! $response->is_success() ) {
      print (STDERR "Error fetching data: "
	     . $response->code . " :: " . status_message($response->code) . "\n");
      print STDERR "------\n" . $response->decoded_content . "\n------\n";
      print STDERR "  URI: '$uri'\n" if ( $verbose > 1 );
    }
    else {
      printf (STDERR "%s\n", ($nobsprint)?sizestring($datasize):"") if ( $verbose );
    }

    # Add data bytes to global total
    $totalbytes += $datasize;

    close OUT;

    # Remove file if no data was fetched
    unlink $sacpzfile if ( $datasize == 0 );
  }

  my $duration = Time::HiRes::time - $ftime;
  my $rate = $totalbytes/(($duration)?$duration:0.000001);
  printf (STDERR "Received %s of SAC P&Zs in %.1f seconds (%s/s)\n",
	  sizestring($totalbytes), $duration, sizestring($rate));

} # End of FetchSACPZ


######################################################################
# FetchRESP:
#
# Fetch SEED RESP for each entry in the %request hash with a value of
# 1.  The result for each channel is written to a separate file in the
# specified directory.
#
######################################################################
sub FetchRESP {
  # Create HTTP user agent
  my $ua = RequestAgent->new();
  $ua->env_proxy;

  my $count = 0;
  my $total = 0;
  foreach my $req ( keys %request ) { $total++ if ( defined $request{$req} ); }

  print STDERR "Fetching RESP\n" if ( $verbose );
  my $ftime = Time::HiRes::time;
  my $totalbytes = 0;

  foreach my $req ( sort keys %request ) {
    # Skip entries with values not set to 1, perhaps no data was fetched
    next if ( ! defined $request{$req} );

    my ($rnet,$rsta,$rloc,$rchan,$rstart,$rend) = split (/\|/, $req);
    my ($mstart,$mend) = split (/\|/, $request{$req});
    $count++;

    # Translate metadata location ID from "--" to blank
    my $ploc = ( $rloc eq "--" ) ? "" : $rloc;

    # Generate output file name and open
    my $respfile = "$respdir/RESP.$rnet.$rsta.$ploc.$rchan";
    if ( ! open (OUT, ">$respfile") ) {
      print STDERR "Cannot open output file '$respfile': $!\n";
      next;
    }

    # Use metadata start and end if not specified
    $rstart = $mstart if ( ! $rstart );
    $rend = $mend if ( ! $rend );

    # Create web service URI
    my $uri = "${respservice}/query?net=$rnet&sta=$rsta&loc=$rloc&cha=$rchan";
    $uri .= "&starttime=$rstart" if ( $rstart );
    $uri .= "&endtime=$rend" if ( $rend );

    print STDERR "RESP URI: '$uri'\n" if ( $verbose > 1 );

    print STDERR "Downloading $respfile ($count/$total) :: " if ( $verbose );

    $datasize = 0;

    # Fetch data from web service using callback routine
    my $response = $ua->get($uri, ':content_cb' => \&DLCallBack );

    if ( $response->code == 404 || $response->code == 204 ) {
      print (STDERR "No data available\n") if ( $verbose );
    }
    elsif ( ! $response->is_success() ) {
      print (STDERR "Error fetching data: "
	     . $response->code . " :: " . status_message($response->code) . "\n");
      print STDERR "------\n" . $response->decoded_content . "\n------\n";
      print STDERR "  URI: '$uri'\n" if ( $verbose > 1 );
    }
    else {
      printf (STDERR "%s\n", ($nobsprint)?sizestring($datasize):"") if ( $verbose );
    }

    # Add data bytes to global total
    $totalbytes += $datasize;

    close OUT;

    # Remove file if no data was fetched
    unlink $respfile if ( $datasize == 0 );
  }

  my $duration = Time::HiRes::time - $ftime;
  my $rate = $totalbytes/(($duration)?$duration:0.000001);
  printf (STDERR "Received %s of RESP in %.1f seconds (%s/s)\n",
	  sizestring($totalbytes), $duration, sizestring($rate));

} # End of FetchRESP


######################################################################
# DLCallBack:
#
# A call back for LWP downloading.
#
# Write received data to output file, tally up the received data size
# and print and updated (overwriting) byte count string.
######################################################################
sub DLCallBack {
  my ($data, $response, $protocol) = @_;
  print OUT $data;
  $datasize += length($data);

  if ( $verbose && ! $nobsprint ) {
    printf (STDERR "%-10.10s\b\b\b\b\b\b\b\b\b\b", sizestring($datasize));
  }
}


######################################################################
# FetchMetaData:
#
# Collect metadata and expand wildcards for selected data set.
#
# Resulting metadata is placed in the global @metadata array with each
# entry taking the following form:
#   "net|sta|loc|chan|start|end|lat|lon|elev|depth|azimuth|dip|instrument|samplerate|sensitivity|sensfreq|sensunits"
#
# In addition, an entry for the unique NSLCQ time-window is added to
# the %request hash, used later to request data.  The value of the
# request hash entries is maintained to be the range of Channel epochs
# that match the time selection.
#
######################################################################
sub FetchMetaData {
  # These our declared with a wider scope for use in the enclosed package
  our ($rnet,$rsta,$rloc,$rchan,$rstart,$rend) = @_;

  # Create HTTP user agent
  my $ua = RequestAgent->new();
  $ua->env_proxy;

  # Create web service URI
  my $uri = "${metadataservice}/query?level=channel";
  $uri .= "&network=$rnet" if ( $rnet );
  $uri .= "&station=$rsta" if ( $rsta );
  $uri .= "&location=$rloc" if ( $rloc );
  $uri .= "&channel=$rchan" if ( $rchan );
  $uri .= "&starttime=$rstart" if ( $rstart );
  $uri .= "&endtime=$rend" if ( $rend );
  if ( scalar @latrange ) {
    $uri .= "&minlat=$latrange[0]" if ( defined $latrange[0] );
    $uri .= "&maxlat=$latrange[1]" if ( defined $latrange[1] );
  }
  if ( scalar @lonrange ) {
    $uri .= "&minlon=$lonrange[0]" if ( defined $lonrange[0] );
    $uri .= "&maxlon=$lonrange[1]" if ( defined $lonrange[1] );
  }
  if ( scalar @degrange ) {
    $uri .= "&lat=$degrange[0]" if ( defined $degrange[0] );
    $uri .= "&lon=$degrange[1]" if ( defined $degrange[1] );
    $uri .= "&maxradius=$degrange[2]" if ( defined $degrange[2] );
    $uri .= "&minradius=$degrange[3]" if ( defined $degrange[3] );
  }

  my $ftime = Time::HiRes::time;

  print STDERR "Metadata URI: '$uri'\n" if ( $verbose > 1 );

  print STDERR "Fetching metadata :: " if ( $verbose );

  $datasize = 0;
  $metadataxml = "";

  # Fetch metadata from web service using callback routine
  my $response = $ua->get($uri, ':content_cb' => \&MDCallBack );

  if ( $response->code == 204 ) {
    print (STDERR "No data available\n") if ( $verbose );
    return;
  }
  elsif ( ! $response->is_success() ) {
    print (STDERR "Error fetching data: "
	   . $response->code . " :: " . status_message($response->code) . "\n");
    print STDERR "------\n" . $response->decoded_content . "\n------\n";
    print STDERR "  URI: '$uri'\n" if ( $verbose > 1 );
  }
  else {
    printf (STDERR "%s\n", ($nobsprint)?sizestring($datasize):"") if ( $verbose );
  }

  my $duration = Time::HiRes::time - $ftime;
  my $rate = $datasize/(($duration)?$duration:0.000001);
  printf (STDERR "Received %s of metadata in %.1f seconds (%s/s)\n",
	  sizestring($datasize), $duration, sizestring($rate));

  # Return if no metadata received
  return if ( length $metadataxml <= 0 );

  # Create stream oriented XML parser instance
  use XML::SAX;
  my $parser = new XML::SAX::ParserFactory->parser( Handler => MDSHandler->new );

  my $totalepochs = 0;

  my $ptime = Time::HiRes::time;

  print STDERR "Parsing XML metadata... " if ( $verbose );

  # Open file to store metadata XML
  my $metadataxmlfile = "metadata-$$.xml";
  if ( open (MXML, ">$metadataxmlfile") ) {
    # Write XML and close file
    print MXML $metadataxml;
    close MXML;

    # Parse XML metadata from file
    $parser->parse_file ($metadataxmlfile);

    # Remove temporary XML metadata file
    if ( ! unlink $metadataxmlfile ) {
      print STDERR "Cannot remove temporary XML metadata file: $!\n";
    }
  }
  # Otherwise parse the XML in memory
  else {
    printf STDERR " in memory (possibly slow), " if ( $verbose );

    # Parse XML metadata from string
    $parser->parse_string ($metadataxml);
  }

  printf STDERR "Done (%.1f seconds)\n", Time::HiRes::time - $ptime if ( $verbose );

  my $duration = Time::HiRes::time - $ftime;
  my $rate = $datasize/(($duration)?$duration:0.000001);
  printf (STDERR "Processed metadata for $totalepochs channel epochs in %.1f seconds (%s/s)\n",
	  $duration, sizestring($rate));

  ## End of this routine, below is the XML parsing handler used above

  ## Beginning of SAX MDSHandler, event-based streaming XML parsing
  package MDSHandler;
  use base qw(XML::SAX::Base);
  use HTTP::Date;

  my $inchannel = 0;
  my $inlat = 0;
  my $inlon = 0;
  my $inelevation = 0;
  my $indepth = 0;
  my $inazimuth = 0;
  my $indip = 0;
  my $insensor = 0;
  my $insensortype = 0;
  my $insamplerate = 0;

  my $ininstsens = 0;
  my $insensvalue = 0;
  my $insensfreq = 0;
  my $ininputunits = 0;
  my $inunitname = 0;

  my ($net,$sta,$loc,$chan,$start,$end,$lat,$lon,$elev,$depth,$azimuth,$dip,$instrument,$samplerate,$sens,$sensfreq,$sensunit) = (undef) x 17;

  sub start_element {
    my ($self,$element) = @_;

    if ( $element->{Name} eq "Network" ) {
      $net = $element->{Attributes}->{'{}code'}->{Value};
    }

    elsif ( $element->{Name} eq "Station" ) {
      ($sta,$loc,$chan,$start,$end,$lat,$lon,$elev,$depth,$azimuth,$dip,$instrument,$samplerate,$sens,$sensfreq,$sensunit) = (undef) x 16;

      $sta = $element->{Attributes}->{'{}code'}->{Value};
    }

    elsif ( $element->{Name} eq "Channel" ) {
      $loc = $element->{Attributes}->{'{}locationCode'}->{Value};
      $chan = $element->{Attributes}->{'{}code'}->{Value};
      $start = $element->{Attributes}->{'{}startDate'}->{Value};
      $end = $element->{Attributes}->{'{}endDate'}->{Value};
      $inchannel = 1;
    }

    if ( $inchannel ) {
      if ( $element->{Name} eq "Latitude" ) { $inlat = 1; }
      elsif ( $element->{Name} eq "Longitude" ) { $inlon = 1; }
      elsif ( $element->{Name} eq "Elevation" ) { $inelevation = 1; }
      elsif ( $element->{Name} eq "Depth" ) { $indepth = 1; }
      elsif ( $element->{Name} eq "Azimuth" ) { $inazimuth = 1; }
      elsif ( $element->{Name} eq "Dip" ) { $indip = 1; }
      elsif ( $element->{Name} eq "SampleRate" ) { $insamplerate = 1; }
      elsif ( $element->{Name} eq "Sensor" ) { $insensor = 1; }
      elsif ( $element->{Name} eq "InstrumentSensitivity" ) { $ininstsens = 1; }
    }

    if ( $insensor ) {
      if ( $element->{Name} eq "Type" ) { $insensortype = 1; }
    }

    if ( $ininstsens ) {
      if ( $element->{Name} eq "Value" ) { $insensvalue = 1; }
      elsif ( $element->{Name} eq "Frequency" ) { $insensfreq = 1; }
      elsif ( $element->{Name} eq "InputUnits" ) { $ininputunits = 1; }
    }

    if ( $ininputunits ) {
      if ( $element->{Name} eq "Name" ) { $inunitname = 1; }
    }
  }

  sub end_element {
    my ($self,$element) = @_;

    if ( $element->{Name} eq "Network" ) {
      $net = 0;
    }

    elsif ( $element->{Name} eq "Station" ) {
      $sta = 0;
    }

    elsif ( $element->{Name} eq "Channel" ) {
      # Track epoch count
      $totalepochs++;

      # Translate metadata location ID to "--" if it's spaces
      my $dloc = ( $loc eq "  " ) ? "--" : $loc;

      # Remove newlines, returns and trailing spaces in metadata instrument name
      $instrument =~ s/[\n\r]//g;
      $instrument =~ s/\s*$//g;

      # Cleanup start and end strings, with truncation to 2038-01-01T00:00:00 for older Perls
      my ($y,$mo,$d,$h,$m,$s) = $start =~ /^(\d{4,4})[-\/,:](\d{1,2})[-\/,:](\d{1,2})[-\/,:T](\d{1,2})[-\/,:](\d{1,2})[-\/,:](\d{1,2}).*/;
      my $mstart = ( $y >= 2038 ) ? "2038-01-01T00:00:00" : sprintf ("%04d-%02d-%02dT%02d:%02d:%02d", $y,$mo,$d,$h,$m,$s);
      my ($y,$mo,$d,$h,$m,$s) = $end   =~ /^(\d{4,4})[-\/,:](\d{1,2})[-\/,:](\d{1,2})[-\/,:T](\d{1,2})[-\/,:](\d{1,2})[-\/,:](\d{1,2}).*/;
      my $mend =   ( $y >= 2038 ) ? "2038-01-01T00:00:00" : sprintf ("%04d-%02d-%02dT%02d:%02d:%02d", $y,$mo,$d,$h,$m,$s);

      # Push channel epoch metadata into storage array
      push (@metadata, "$net|$sta|$dloc|$chan|$start|$end|$lat|$lon|$elev|$depth|$azimuth|$dip|$instrument|$samplerate|$sens|$sensfreq|$sensunit");

      # Put entry into request hash, value is the widest range of channel epochs
      if ( ! exists  $request{"$net|$sta|$dloc|$chan|$rstart|$rend"} ) {
	$request{"$net|$sta|$dloc|$chan|$rstart|$rend"} = "$mstart|$mend";
      }
      else {
	# Track widest metadata start and end range
	my ($vstart,$vend) = split (/\|/, $request{"$net|$sta|$dloc|$chan|$rstart|$rend"});
	my $startepoch = str2time ($mstart);
	my $endepoch = str2time ($mend);
	$vstart = $mstart if ( $startepoch < str2time ($vstart) );
	$vend = $mend if ( $endepoch > str2time ($vend) );
	$request{"$net|$sta|$dloc|$chan|$rstart|$rend"} = "$vstart|$vend";
      }

      # Reset Channel level fields
      ($loc,$chan,$start,$end,$lat,$lon,$elev,$depth,$azimuth,$dip,$instrument,$samplerate,$sens,$sensfreq,$sensunit) = (undef) x 15;

      $inchannel = 0;
    }

    if ( $inchannel ) {
      if ( $element->{Name} eq "Latitude" ) { $inlat = 0; }
      elsif ( $element->{Name} eq "Longitude" ) { $inlon = 0; }
      elsif ( $element->{Name} eq "Elevation" ) { $inelevation = 0; }
      elsif ( $element->{Name} eq "Depth" ) { $indepth = 0; }
      elsif ( $element->{Name} eq "Azimuth" ) { $inazimuth = 0; }
      elsif ( $element->{Name} eq "Dip" ) { $indip = 0; }
      elsif ( $element->{Name} eq "SampleRate" ) { $insamplerate = 0; }
      elsif ( $element->{Name} eq "Sensor" ) { $insensor = 0; }
      elsif ( $element->{Name} eq "InstrumentSensitivity" ) { $ininstsens = 0; }
    }

    if ( $insensor ) {
      if ( $element->{Name} eq "Type" ) { $insensortype = 0; }
    }

    if ( $ininstsens ) {
      if ( $element->{Name} eq "Value" ) { $insensvalue = 0; }
      elsif ( $element->{Name} eq "Frequency" ) { $insensfreq = 0; }
      elsif ( $element->{Name} eq "InputUnits" ) { $ininputunits = 0; }
    }

    if ( $ininputunits ) {
      if ( $element->{Name} eq "Name" ) { $inunitname = 0; }
    }
  }

  sub characters {
    my ($self,$element) = @_;

    if ( defined $element->{Data} ) {
      if ( $inlat ) { $lat .= $element->{Data}; }
      elsif ( $inlon ) { $lon .= $element->{Data}; }
      elsif ( $inelevation ) { $elev .= $element->{Data}; }
      elsif ( $indepth ) { $depth .= $element->{Data}; }
      elsif ( $inazimuth ) { $azimuth .= $element->{Data}; }
      elsif ( $indip ) { $dip .= $element->{Data}; }
      elsif ( $insamplerate ) { $samplerate .= $element->{Data}; }

      elsif ( $insensortype ) { $instrument .= $element->{Data}; }

      elsif ( $insensvalue ) { $sens .= $element->{Data}; }
      elsif ( $insensfreq ) { $sensfreq .= $element->{Data}; }
      elsif ( $inunitname ) { $sensunit .= $element->{Data}; }
    }
  } # End of SAX MDSHandler
} # End of FetchMetaData()


######################################################################
# MDCallBack:
#
# A call back for LWP downloading of metadata.
#
# Add received data to metadataxml string, tally up the received data
# size and print and updated (overwriting) byte count string.
######################################################################
sub MDCallBack {
  my ($data, $response, $protocol) = @_;
  $metadataxml .= $data;
  $datasize += length($data);

  if ( $verbose && ! $nobsprint ) {
    printf (STDERR "%-10.10s\b\b\b\b\b\b\b\b\b\b", sizestring($datasize));
  }
}


######################################################################
# sizestring (bytes):
#
# Return a clean size string for a given byte count.
######################################################################
sub sizestring { # sizestring (bytes)
  my $bytes = shift;

  if ( $bytes < 1000 ) {
    return sprintf "%d Bytes", $bytes;
  }
  elsif ( ($bytes / 1024) < 1000 ) {
    return sprintf "%.1f KB", $bytes / 1024;
  }
  elsif ( ($bytes / 1024 / 1024) < 1000 ) {
    return sprintf "%.1f MB", $bytes / 1024 / 1024;
  }
  elsif ( ($bytes / 1024 / 1024 / 1024) < 1000 ) {
    return sprintf "%.1f GB", $bytes / 1024 / 1024 / 1024;
  }
  elsif ( ($bytes / 1024 / 1024 / 1024 / 1024) < 1000 ) {
    return sprintf "%.1f TB", $bytes / 1024 / 1024 / 1024 / 1024;
  }
  else {
    return "";
  }
} # End of sizestring()


######################################################################
#
# Package RequestAgent: a superclass for LWP::UserAgent with override
# of LWP::UserAgent methods to set default user agent and handle
# authentication credentials.
#
######################################################################
BEGIN {
  use LWP;
  package RequestAgent;
  our @ISA = qw(LWP::UserAgent);

  sub new
    {
      my $self = LWP::UserAgent::new(@_);
      my $fulluseragent = $useragent;
      $fulluseragent .= " ($appname)" if ( $appname );
      $self->agent($fulluseragent);
      $self;
    }

  sub get_basic_credentials
    {
      my ($self, $realm, $uri) = @_;

      if ( defined $auth ) {
        return split(':', $auth, 2);
      }
      elsif (-t) {
        my $netloc = $uri->host_port;
        print "\n";
        print "Enter username for $realm at $netloc: ";
        my $user = <STDIN>;
        chomp($user);
        return (undef, undef) unless length $user;
        print "Password: ";
        system("stty -echo");
        my $password = <STDIN>;
        system("stty echo");
        print "\n";  # because we disabled echo
        chomp($password);
        return ($user, $password);
      }
      else {
        return (undef, undef)
      }
    }
} # End of LWP::UserAgent override

